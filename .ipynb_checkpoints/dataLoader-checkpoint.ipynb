{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from os import walk\n",
    "import pymysql\n",
    "\n",
    "########################################################################\n",
    "# Function for importing data\n",
    "########################################################################\n",
    "\n",
    "# I put this as function to make testing easier\n",
    "# rootDir is the directory where data and spec folder is located\n",
    "def dataImports(db, cursor, BATCH_SIZE, rootDir):\n",
    "    \n",
    "    specDir = rootDir + \"specs/\"\n",
    "    dataDir = rootDir + \"data/\"\n",
    "    \n",
    "    # List of Problematic file, for debugging\n",
    "    problematicFile = []\n",
    "\n",
    "    print(\"Selecting data to load...\")\n",
    "    dataToLoad, problematicFile = getDataToLoad(rootDir)\n",
    "\n",
    "    print()\n",
    "    print(\"Loading data...\")\n",
    "    \n",
    "    # Prepare create table SQL statement for spec files\n",
    "    for tableName in dataToLoad:\n",
    "        sqlStatement = \"\"\n",
    "        spec = []\n",
    "        try:\n",
    "            with open( specDir + tableName + \".csv\", \"r\", encoding=\"utf-8\") as specFile:\n",
    "                spec, sqlStatement = prepareCreateTableStatement(tableName, specFile)\n",
    "\n",
    "            # execute the create table statement\n",
    "            cursor.execute(sqlStatement)\n",
    "        except Exception as e:\n",
    "            print(\"Exception occured:{}\".format(e))\n",
    "            print(\"Problem with creating table for definition\", tableName, \", Skipping this specs\" )\n",
    "            problematicFile.append(specDir + tableName + \".csv\")\n",
    "\n",
    "            # since the data file is not processed as well\n",
    "            for data in dataToLoad[tableName]:\n",
    "                problematicFile.append(dataDir + data)\n",
    "        else:\n",
    "            # commit the create table statement\n",
    "            db.commit()\n",
    "            print(\"Table ready for\", tableName)\n",
    "\n",
    "            # Prepare insert data SQL statement for data files\n",
    "            for data in dataToLoad[tableName]:\n",
    "                with open(dataDir + data, \"r\", encoding=\"utf-8\") as dataFile:\n",
    "                    insertions = prepareInsertStatement(tableName, dataFile, BATCH_SIZE, spec)\n",
    "\n",
    "                # Execute the data insertion\n",
    "                totalCount = 0\n",
    "                for batch in insertions:\n",
    "                    try:\n",
    "                        # execute the insert data statement\n",
    "                        cursor.execute(batch[\"statement\"])\n",
    "                    except Exception as e:\n",
    "                        print()\n",
    "                        print(\"Exception occured:{}\".format(e))\n",
    "                        print(\"Problem with creating table for data file\", data, \", Skipping this file and rollbacking this file\" )\n",
    "                        problematicFile.append(dataDir + data)\n",
    "\n",
    "                        # if some data input fail, rollback changes in this file\n",
    "                        db.rollback()\n",
    "                        totalCount = 0\n",
    "                        break\n",
    "                    else:\n",
    "                        totalCount += batch[\"count\"]\n",
    "                        \n",
    "                # commit the insertion\n",
    "                db.commit()\n",
    "                print(totalCount, \"rows from\", data, \"are inserted\")\n",
    "                \n",
    "            print()\n",
    "\n",
    "    return problematicFile\n",
    "\n",
    "# Check the specs and data dir to pre choose which files to use in the importing process\n",
    "def getDataToLoad(rootDir):\n",
    "    \n",
    "    specDir = rootDir + \"specs/\"\n",
    "    dataDir = rootDir + \"data/\"\n",
    "    \n",
    "    dataToLoad = dict()\n",
    "    problematicFile = []\n",
    "    \n",
    "    # Get list of definition\n",
    "    for (dirpath, dirnames, filenames) in walk(specDir):\n",
    "        for file in filenames:\n",
    "            dataToLoad[file[:-4]] = []\n",
    "\n",
    "    # Get list of data and assign to spec\n",
    "    for (dirpath, dirnames, filenames) in walk(dataDir):\n",
    "        for file in filenames:\n",
    "            tableName = file[:-15]\n",
    "\n",
    "            # Ignore file without corresponding spec file\n",
    "            if tableName in dataToLoad.keys():\n",
    "                dataToLoad[tableName].append(file)\n",
    "            else:\n",
    "                print(\"Ignoring data file\", file, \"as no corresponding spec file exist\")\n",
    "                problematicFile.append(dataDir + file)\n",
    "\n",
    "    # Preventing dictionary changed size during iteration error\n",
    "    ignoredSpecList = []\n",
    "    for dataFile in dataToLoad:\n",
    "        if len(dataToLoad[dataFile]) == 0 :\n",
    "            ignoredSpecList.append(dataFile)\n",
    "            print(\"Ignoring spec file\", dataFile + \".csv\" , \"as no corresponding data file exist\")\n",
    "            problematicFile.append(specDir + dataFile + \".csv\")\n",
    "\n",
    "    # Ignore spec file with no data file\n",
    "    for dataFile in ignoredSpecList:\n",
    "        del dataToLoad[dataFile]\n",
    "\n",
    "    return dataToLoad, problematicFile\n",
    "\n",
    "# Process spec file, returning the specification elements and create table statement\n",
    "def prepareCreateTableStatement(tableName, specFile):\n",
    "    spec = []\n",
    "    \n",
    "    # Skip the header\n",
    "    next(specFile)\n",
    "\n",
    "    # Prepare statement with id as primary key\n",
    "    sqlStatement = \"CREATE TABLE IF NOT EXISTS `\" + tableName + \"` (\"\n",
    "    \n",
    "    # Naming primary key to tablename_id format to make working with it easier            \n",
    "    sqlStatement += \"`\" + tableName + \"_id` INT(11) NOT NULL auto_increment, \"\n",
    "\n",
    "    for line in specFile:\n",
    "        specAttr = {}\n",
    "        line = line.strip().split(',')\n",
    "\n",
    "        # Formatting, personally I prefer all DB field name to be standardized\n",
    "        # to lowercase and snake case\n",
    "        colName = line[0].strip().lower().replace(\" \", \"_\")\n",
    "        length = line[1].strip()\n",
    "        dataType = line[2].strip()\n",
    "\n",
    "        specAttr[\"colName\"] = colName\n",
    "        specAttr[\"length\"] = int(length)\n",
    "        specAttr[\"type\"] = dataType\n",
    "\n",
    "        sqlStatement += \"`\" + colName + \"` \"\n",
    "\n",
    "        if dataType == \"TEXT\":\n",
    "            sqlStatement += \"VARCHAR(\" + length + \")\"\n",
    "        elif dataType == \"FLOAT\":\n",
    "            sqlStatement += \"DOUBLE\"\n",
    "        elif dataType == \"DATETIME\":\n",
    "            sqlStatement += \"VARCHAR(20)\"\n",
    "        elif dataType == \"BOOLEAN\":\n",
    "            sqlStatement += \"tinyint(1)\"\n",
    "        elif dataType == \"INTEGER\":\n",
    "            # Might need to handle different number of digits in the future here                \n",
    "            sqlStatement += \"INT(\" + length + \")\"\n",
    "        else:\n",
    "            # Unknown Integer!\n",
    "            raise Exception('unknown format in spec file ' + tableName)\n",
    "\n",
    "        # Might need to add default value for table here  \n",
    "        sqlStatement += \", \"\n",
    "        spec.append(specAttr)\n",
    "\n",
    "    sqlStatement += \"PRIMARY KEY (`\" + tableName + \"_id`) );\"\n",
    "    \n",
    "    return spec, sqlStatement\n",
    "\n",
    "# Process Data file input and prepare sql insert statements\n",
    "# it will break down large file input into batch to prevent mysql error\n",
    "def prepareInsertStatement(tableName, dataFile, batchSize, spec):\n",
    "    \n",
    "    # Prepare the header\n",
    "    columnList = [] \n",
    "    for specAttr in spec:\n",
    "        columnList.append(specAttr[\"colName\"])\n",
    "    insertColumnStatement = \"INSERT INTO \" + tableName + \" (\" + \", \".join(columnList) + \") VALUES\"\n",
    "    \n",
    "    insertion = []\n",
    "    \n",
    "    count = 0\n",
    "    rows = []\n",
    "\n",
    "    for line in dataFile:  \n",
    "        position = 0\n",
    "        \n",
    "        fieldList = []\n",
    "        for field in spec:\n",
    "            value = line[position : (position + field[\"length\"])] \n",
    "            \n",
    "            if field[\"type\"] == \"TEXT\" or field[\"type\"] == \"DATETIME\" :\n",
    "                fieldList.append(\"'\" + value.strip() + \"'\")\n",
    "            else :\n",
    "                fieldList.append(value.strip())\n",
    "                \n",
    "            position += field[\"length\"] \n",
    "\n",
    "        rows.append(\"(\" + \", \".join(fieldList) + \")\")\n",
    "        count += 1\n",
    "        \n",
    "        if count >= batchSize:\n",
    "            # when the data get too big, separate it to different statements\n",
    "            batch = {}\n",
    "            batch[\"count\"] = count\n",
    "            batch[\"statement\"] = insertColumnStatement + \", \".join(rows)\n",
    "            insertion.append(batch)\n",
    "            \n",
    "            count = 0\n",
    "            rows = []\n",
    "    \n",
    "    if count > 0 : \n",
    "        batch = {}\n",
    "        batch[\"count\"] = count\n",
    "        batch[\"statement\"] = insertColumnStatement + \", \".join(rows)\n",
    "        insertion.append(batch)\n",
    "\n",
    "    return insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Utility\n",
    "######################################################################## \n",
    "\n",
    "# A helper function that read the config file and load it to memory\n",
    "def getConfig():\n",
    "    \n",
    "    # defaults\n",
    "    dbConfig = {}\n",
    "    dbConfig[\"host\"] = \"localhost\"\n",
    "    dbConfig[\"user\"] = \"root\"\n",
    "    dbConfig[\"password\"] = \"\"\n",
    "    dbConfig[\"port\"] = 3306\n",
    "    BATCH_SIZE=100\n",
    "    \n",
    "    try:\n",
    "        with open(\"config.txt\", \"r\", encoding=\"utf-8\") as configFile:\n",
    "            config = {}\n",
    "            for line in configFile:\n",
    "                line = line.strip().split(\"=\")\n",
    "                if line[0] != \"\":\n",
    "                    config[line[0]] = line[1]\n",
    "                    \n",
    "        dbConfig[\"host\"] = config[\"DB_HOST\"]\n",
    "        dbConfig[\"port\"] = int(config[\"DB_PORT\"])\n",
    "        \n",
    "        dbConfig[\"user\"] = config[\"DB_USERNAME\"]\n",
    "        dbConfig[\"password\"] = config[\"DB_PASSWORD\"]\n",
    "        \n",
    "        dbConfig[\"dbName\"] = config[\"DB_DBNAME\"]\n",
    "        BATCH_SIZE = int(config[\"DB_INSERT_BATCH_SIZE\"])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Exception occured:{}\".format(e))\n",
    "        print(\"Config file not exist! Using default parameters\" )\n",
    "        \n",
    "    return dbConfig, BATCH_SIZE\n",
    "\n",
    "\n",
    "# a function that try to connec to the database\n",
    "def connectToDatabaseAndGetCursor(dbConfig, dbName):\n",
    "    db = None\n",
    "    cursor = None\n",
    "    fail = False\n",
    "    \n",
    "    try: \n",
    "        # try to conect to db\n",
    "        db = pymysql.connect(host = dbConfig[\"host\"], user = dbConfig[\"user\"], password = dbConfig[\"password\"], port = dbConfig[\"port\"])\n",
    "    except Exception as e:\n",
    "        print(\"Exception occured:{}\".format(e))\n",
    "        fail = True\n",
    "    else:\n",
    "        cursor = db.cursor()\n",
    "        # try to create a DB called 'dataDB'\n",
    "        try:\n",
    "            # use test database for testing\n",
    "            cursor.execute(\"create database IF NOT EXISTS \" + dbName)\n",
    "            cursor.execute(\"use \" + dbName)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Exception occured:{}\".format(e))\n",
    "            fail = True\n",
    "    \n",
    "    return db, cursor, fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting data to load...\n",
      "Ignoring data file testformat3_2015-06-28.txt as no corresponding spec file exist\n",
      "Ignoring spec file dummy.csv as no corresponding data file exist\n",
      "\n",
      "Loading data...\n",
      "Table ready for testformat1\n",
      "3 rows from testformat1_2015-06-29.txt are inserted\n",
      "144 rows from testformat1_2015-06-28.txt are inserted\n",
      "\n",
      "Table ready for claims\n",
      "2 rows from claims_2015-06-29.txt are inserted\n",
      "2 rows from claims_2015-06-28.txt are inserted\n",
      "\n",
      "Some file/specs are not loaded, here is the list of unprocessed data\n",
      "data/testformat3_2015-06-28.txt\n",
      "specs/dummy.csv\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Entry point\n",
    "# Run by using `python3 dataLoader.py` in bash\n",
    "########################################################################\n",
    "def main():\n",
    "    \n",
    "    # CONFIG \n",
    "    dbConfig, BATCH_SIZE = getConfig()\n",
    "    \n",
    "    # Connect to Database\n",
    "    db, cursor, fail = connectToDatabaseAndGetCursor(dbConfig, dbConfig[\"dbName\"])\n",
    "    \n",
    "    if not fail:\n",
    "        problematicFile = dataImports(db, cursor, BATCH_SIZE, \"\")\n",
    "        db.close()\n",
    "        \n",
    "        if len(problematicFile)  == 0:\n",
    "            print(\"All file loaded successfully\")\n",
    "        else:\n",
    "            print(\"Some file/specs are not loaded, here is the list of unprocessed data\")\n",
    "            for file in problematicFile:\n",
    "                print(file)\n",
    "                \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting data to load...\n",
      "\n",
      "Loading data...\n",
      "Table ready for testformat1\n",
      "3 rows from testformat1_2015-06-28.txt are inserted\n",
      "\n",
      "Table ready for testformat2\n",
      "1152 rows from testformat2_2015-06-28.txt are inserted\n",
      "\n",
      "Table ready for claims\n",
      "2 rows from claims_2015-06-28.txt are inserted\n",
      "\n",
      "PASS --- happyFlow\n",
      "\n",
      "Selecting data to load...\n",
      "Ignoring data file testformat2_2015-06-28.txt as no corresponding spec file exist\n",
      "Ignoring spec file claims.csv as no corresponding data file exist\n",
      "\n",
      "Loading data...\n",
      "Exception occured:unknown format in spec file testformat3\n",
      "Problem with creating table for definition testformat3 , Skipping this specs\n",
      "['testData/catchNonMatchingSpecAndDataFile/data/testformat2_2015-06-28.txt', 'testData/catchNonMatchingSpecAndDataFile/specs/claims.csv', 'testData/catchNonMatchingSpecAndDataFile/specs/testformat3.csv', 'testData/catchNonMatchingSpecAndDataFile/data/testformat3_2015-06-29.txt', 'testData/catchNonMatchingSpecAndDataFile/data/testformat3_2015-06-28.txt', 'testData/catchNonMatchingSpecAndDataFile/data/testformat3_2015-06-30.txt']\n",
      "Exception occured:(1146, \"Table 'testDB.testformat3' doesn't exist\")\n",
      "FAIL --- catchNonMatchingSpecAndDataFile\n",
      "\n",
      "Selecting data to load...\n",
      "\n",
      "Loading data...\n",
      "Table ready for testformat1\n",
      "\n",
      "Exception occured:(1054, \"Unknown column 'a03' in 'field list'\")\n",
      "Problem with creating table for data file testformat1_2015-06-28.txt , Skipping this file and rollbacking this file\n",
      "0 rows from testformat1_2015-06-28.txt are inserted\n",
      "\n",
      "Table ready for testformat2\n",
      "\n",
      "Exception occured:(1054, \"Unknown column 'a1' in 'field list'\")\n",
      "Problem with creating table for data file testformat2_2015-06-28.txt , Skipping this file and rollbacking this file\n",
      "0 rows from testformat2_2015-06-28.txt are inserted\n",
      "\n",
      "PASS --- rollbackWhenDataIsCorrupted\n",
      "\n",
      "TEST CASE FAIL\n",
      "Noooo! you broke something\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# Test Files\n",
    "########################################################################\n",
    "def integrationTest():\n",
    "    \n",
    "    # TEST RESULT\n",
    "    success = True\n",
    "    \n",
    "    # CONFIG \n",
    "    dbConfig, BATCH_SIZE = getConfig()\n",
    "    \n",
    "    success = runTestCase(happyFlow, dbConfig, 100) and success\n",
    "    success = runTestCase(catchNonMatchingSpecAndDataFile, dbConfig, 100) and success\n",
    "    success = runTestCase(rollbackWhenDataIsCorrupted, dbConfig, 100) and success\n",
    "    \n",
    "    if success :\n",
    "        print(\"TEST CASE PASS\")\n",
    "        print(\"Yay! all test case passed\")\n",
    "    else:\n",
    "        print(\"TEST CASE FAIL\")\n",
    "        print(\"Noooo! you broke something\")\n",
    "\n",
    "# Happy Flow test case\n",
    "def happyFlow(testName, db, cursor, BATCH_SIZE):\n",
    "    problematicFile = dataImports(db, cursor, 100, \"testData/\" + testName + \"/\")\n",
    "    assert len(problematicFile) == 0\n",
    "    \n",
    "    # Baseline test\n",
    "    cursor.execute(\"SELECT * from testformat1\")\n",
    "    rows = cursor.fetchall()\n",
    "    assert str(rows) == \"((1, 'Yooofrn', 1, 1), (2, 'Zneabar', 0, -12), (3, 'Uuietdxuq', 1, 103))\", \"testformat1\"\n",
    "    \n",
    "    # test if it can success fully insert large amount of data (batch size is 100)\n",
    "    cursor.execute(\"SELECT * from testformat2\")\n",
    "    rows = cursor.fetchall()\n",
    "    assert len(rows) == 1152, \"testformat2\"\n",
    "    \n",
    "    # test if it can handle floating point and other data types\n",
    "    cursor.execute(\"SELECT * from claims\")\n",
    "    rows = cursor.fetchall()\n",
    "    assert str(rows) == \"((1, '1234567890', 15.0, '2015-06-08T10:08:03Z', 0, 'Stephen'), (2, '1234567891', -15.0, '2015-06-18T10:08:03Z', 1, 'Curry'))\", \"claims\"\n",
    "\n",
    "# Happy Flow test case\n",
    "def catchNonMatchingSpecAndDataFile(testName, db, cursor, BATCH_SIZE):\n",
    "    problematicFile = dataImports(db, cursor, BATCH_SIZE, \"testData/\" + testName + \"/\")\n",
    "    assert len(problematicFile) == 6, \"there should be 6 ignored files\"\n",
    "    \n",
    "    # No spec file\n",
    "    assert problematicFile[0] == 'testData/catchNonMatchingSpecAndDataFile/data/testformat2_2015-06-28.txt',\"problematicFile output\"\n",
    "    # No data file\n",
    "    assert problematicFile[1] == 'testData/catchNonMatchingSpecAndDataFile/specs/claims.csv',\"problematicFile output\"\n",
    "    # Spec file corrupt\n",
    "    assert problematicFile[2] == 'testData/catchNonMatchingSpecAndDataFile/specs/testformat3.csv', \"problematicFile output\"\n",
    "    assert problematicFile[3] == 'testData/catchNonMatchingSpecAndDataFile/data/testformat3_2015-06-29.txt', \"problematicFile output\"\n",
    "    assert problematicFile[4] == 'testData/catchNonMatchingSpecAndDataFile/data/testformat3_2015-06-28.txt', \"problematicFile output\"\n",
    "    assert problematicFile[5] == 'testData/catchNonMatchingSpecAndDataFile/data/testformat3_2015-06-30.txt', \"problematicFile output\"\n",
    "        \n",
    "    # Spec file corrupted\n",
    "    cursor.execute(\"SELECT * from testformat3\")\n",
    "    rows = cursor.fetchall()\n",
    "    print(rows)\n",
    "    assert len(rows) == 0, \"should have nothing as spec file is corrupted\"\n",
    "    \n",
    "# Happy Flow test case\n",
    "def rollbackWhenDataIsCorrupted(testName, db, cursor, BATCH_SIZE):\n",
    "    problematicFile = dataImports(db, cursor, BATCH_SIZE, \"testData/\" + testName + \"/\")\n",
    "    assert len(problematicFile) == 2, \"problematicFile\"\n",
    "    assert problematicFile[0] == 'testData/rollbackWhenDataIsCorrupted/data/testformat1_2015-06-28.txt', \"problematicFile\"\n",
    "    assert problematicFile[1] == 'testData/rollbackWhenDataIsCorrupted/data/testformat2_2015-06-28.txt', \"problematicFile\"\n",
    "       \n",
    "    # Line 177 is corrupted\n",
    "    cursor.execute(\"SELECT * from testformat1\")\n",
    "    rows = cursor.fetchall()\n",
    "    assert len(rows) == 0, \"testformat1\"\n",
    "    \n",
    "    # first line is corrupted\n",
    "    cursor.execute(\"SELECT * from testformat2\")\n",
    "    rows = cursor.fetchall()\n",
    "    assert len(rows) == 0, \"testformat2\"\n",
    "    \n",
    "# Helper function to run the test cases\n",
    "def runTestCase(f, dbConfig, BATCH_SIZE) : \n",
    "    testName =  f.__name__\n",
    "    # Connect to Database\n",
    "    db, cursor, fail = connectToDatabaseAndGetCursor(dbConfig, \"testDB\")\n",
    "    \n",
    "    try:\n",
    "        f(testName, db, cursor, BATCH_SIZE)\n",
    "    except AssertionError as e:\n",
    "        print(\"ASSERTION ERROR occured:{}\".format(e))\n",
    "        success = False\n",
    "    except Exception as e:    \n",
    "        print(\"Exception occured:{}\".format(e))\n",
    "        success = False\n",
    "    else:\n",
    "        success = True\n",
    "    \n",
    "    if success:\n",
    "        print(\"PASS --- \" + testName)\n",
    "    else:\n",
    "        print(\"FAIL --- \" + testName)\n",
    "        \n",
    "    cursor.execute(\"DROP DATABASE `testDB`;\")\n",
    "    db.close()\n",
    "    print()\n",
    "    return success\n",
    "\n",
    "integrationTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
